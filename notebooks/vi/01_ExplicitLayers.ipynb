{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicit layers in deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is based on [Chapter 1: Introduction - Explicit layers in deep learning](https://implicit-layers-tutorial.org/introduction/) in NeurIPS 2020 tutorial, created by [Zico Kolter](http://zicokolter.com/), [David Duvenaud](http://www.cs.toronto.edu/~duvenaud/), and [Matt Johnson](http://people.csail.mit.edu/mattjj/). During my own learning process, I will use both Vietnamese and English for more comfortable. So if someone reach this notebook/ or repo, you should handle by your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is implicit function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a function is written in the form of\n",
    "\\begin{equation}\n",
    "        y = f(x), \\text{ e.g., } y = 2x^3\n",
    "\\end{equation}\n",
    "is called an \\textbf{explicit function}. \n",
    "\n",
    "And sometimes functions are given in the form \n",
    "\\begin{equation}\n",
    "    y - f(x) = 0 \\text{ e.g., } y - 2x^3 = 0\n",
    "\\end{equation}\n",
    "is called an **implicit function**.\n",
    "\n",
    "In general, **implicit function** are written in a general form as\n",
    "\\begin{equation}\n",
    "    F(y, x) = 0\n",
    "\\end{equation}\n",
    "\n",
    "*Note that*: while we can always change an explicit function into an implicit function (by taking $f(x)$ to the other side of the equality) the reverse is not always true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning and deep learning areas, deep neural networks (or DNN for short) are traditionally built by stacking many layers, such as convolutional layers, self-attention layers, or fully connected layers. And these layers are definitely *implicit* due to their output procedure, which involves taking an exact sequence of operations from input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The criation in studying implicit layers is *specify the conditions that we want the layer’s output to satisfy* instead of specifying how to compute the layer’s output from the input. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering some explicit function $f: \\mathcal{X} \\rightarrow \\mathcal{Z}$ with input $x \\in \\mathcal{X}$, and output $z \\in \\mathcal{Z}$\n",
    "\n",
    "$$\n",
    "z = f(x)\n",
    "$$\n",
    "\n",
    "then an implicit layer would instead be defined via a function $g : \\mathcal{X} \\times \\mathcal{Z} \\rightarrow \\mathbb{R}^n$ (a joint function of both $x$ and $z$), and output of the layer $z$ is requied to *satisfy some constraint* e.g., finding a root of the equation,\n",
    "\n",
    "$$\n",
    "\\text{Finding } z \\quad\\text{ s.t. }\\quad g(x, z) = 0\n",
    "$$\n",
    "\n",
    "And in practice, depending on the representation of $g(x, z)$, above formalism can lead to many problems:\n",
    "- If $g(x, z)$ captures algebraic equations and fixed points $\\rightarrow$ *recurent backprop models* or *deep equilibrium models*.\n",
    "- If $g(x, z)$ captures differential equations $\\rightarrow$ *neural ordinary differential equations*.\n",
    "- If we consider the optimality conditions of optimization problems $\\rightarrow$ *differentiable optimization approaches*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
